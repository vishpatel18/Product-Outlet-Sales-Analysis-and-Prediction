# -*- coding: utf-8 -*-
"""Mini Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o47H0u9waI0EXciOgm9eOOOLuGaoteNL
"""

import numpy as np
import os
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_absolute_error as MAE
from sklearn.metrics import mean_squared_error as MSE
from sklearn.metrics import r2_score as R2
from sklearn.model_selection  import cross_val_score as CVS

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Lasso

from sklearn.metrics import mean_absolute_error as MAE
from sklearn.metrics import mean_squared_error as MSE
from sklearn.metrics import r2_score as R2
from sklearn.model_selection  import cross_val_score as CVS

sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)
pd.options.display.max_columns

import warnings
warnings.filterwarnings("always")
warnings.filterwarnings("ignore")

test = pd.read_csv("/content/Test.csv")
train= pd.read_csv("/content/Train.csv")

train.head()

test.head()

import pandas
filename = '/content/Test.csv'
names = ['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Location_Type','Outlet_Type']
data = pandas.read_csv(filename, names=names)
print(data.shape)

import pandas
filename = '/content/Train.csv'
names = ['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Location_Type','Outlet_Type']
data = pandas.read_csv(filename, names=names)
print(data.shape)

"""To find Column Information:-"""

train.info(verbose=True, null_counts=True)

"""Summary statistics test:-"""

test.describe()

"""Summary statistics train:-"""

train.describe()

"""Check the data types:-"""

test.dtypes

train.dtypes

"""Handling the missing values:-"""

test.isnull().sum()

train.isnull().sum()

print("Train:\n")
print(train.isnull().sum()/train.shape[0] *100,"\n\n")
print("Test:\n")
print(test.isnull().sum()/test.shape[0] *100,"\n\n")

"""Check Value Count for Test and Train:-"""

print("Outlet_Size:\n", test.Outlet_Size.value_counts(), "\n\n")
print("Item_Weight:\n", test.Item_Weight.value_counts(), "\n\n")

print("Outlet_Size:\n", train.Outlet_Size.value_counts(), "\n\n")
print("Item_Weight:\n", train.Item_Weight.value_counts(), "\n\n")

rem_dup = train.drop_duplicates(['Item_Identifier', 'Item_Type'])
print(rem_dup)

"""Impute missing values with Medium the mode value for categorical column: Outlet_size:-"""

train['Outlet_Size'] = train['Outlet_Size'].fillna(
train['Outlet_Size'].dropna().mode().values[0])

test['Outlet_Size'] = test['Outlet_Size'].fillna(
test['Outlet_Size'].dropna().mode().values[0])

"""Check for null values again:-"""

train['Outlet_Size'].isnull().sum()

test['Outlet_Size'].isnull().sum()

"""Univariate Analysis:-"""

train.boxplot(column=['Item_Weight'])
plt.show

plt.hist(train['Item_Weight'])

sns.boxplot(train['Item_Weight'])

#categorical columns:
['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier','Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']

plt.figure(figsize=(4,2))
sns.countplot(x='Item_Fat_Content' , data=train)
plt.xlabel('Item_Fat_Content')
plt.show()

"""Bivariate Analysis:-"""

plt.scatter(train.index,train['Outlet_Establishment_Year'])
plt.show()

sns.scatterplot(x=train.index,y=train['Item_Type'],hue=train['Item_Fat_Content'])

plt.scatter(train.index,train['Outlet_Size'])
plt.show()

"""Check for any missing values left:-"""

print(test.info())
print("\n")
print(train.info())

print(test.isnull().sum())

# Outlet_Size
categorical_column = 'Outlet_Size'
# Check if there are missing values in the 'Outlet_Size' column
if test[categorical_column].isnull().any():
    mode_value = test[categorical_column].mode().iloc[0]
    test[categorical_column].fillna(mode_value, inplace=True)

"""Label Encoding:-"""

train['Item_Fat_Content'].replace(['LF', 'low fat', 'reg'],['Low Fat','Low Fat','Regular'],inplace = True)

test['Item_Fat_Content'].replace(['LF', 'low fat', 'reg'],['Low Fat','Low Fat','Regular'],inplace = True)

#check result
train.Item_Fat_Content.value_counts()

train.head()

test.head()

#creating our new column for both datasets
train['Outlet_Age'], test['Outlet_Age']= train['Outlet_Establishment_Year'].apply(lambda year: 2020 - year), test['Outlet_Establishment_Year'].apply(lambda year: 2020 - year)

train['Outlet_Age'].head
test['Outlet_Age'].head

#list of all the numeric columns
num = train.select_dtypes('number').columns.to_list()
#numeric df
BM_num =  train[num]

plt.hist(train['Outlet_Age'])
plt.title("Outlet_Age")
plt.show()

#because of the variability of the unique values of the numeric columns a scatter plot with the target value will be of use
for numeric in BM_num[num[:3]]:
    plt.scatter(BM_num[numeric], BM_num['Item_Outlet_Sales'])
    plt.title(numeric)
    plt.ylabel('Item_Outlet_Sales')
    plt.show()

"""Modelling:-"""

y = train['Item_Outlet_Sales']
X = train.drop('Item_Outlet_Sales', axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8, random_state = 0)

def cross_val(model_name,model,X,y,cv):

    scores = CVS(model, X, y, cv=cv)
    print(f'{model_name} Scores:')
    for i in scores:
        print(round(i,2))
    print(f'Average {model_name} score: {round(scores.mean(),4)}')

#lable encoding

le = LabelEncoder()
Label = ['Item_Fat_Content','Outlet_Size','Outlet_Location_Type']

for i in Label:
    train[i] = le.fit_transform(train[i])
    test[i] = le.fit_transform(test[i])

train.head()



#one hot encoding
cols = ['Item_Type','Outlet_Type']
# Apply one-hot encoder
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
tr_oh = pd.DataFrame(OH_encoder.fit_transform(train[cols])).astype('int64')
te_oh = pd.DataFrame(OH_encoder.fit_transform(test[cols])).astype('int64')


#get feature columns
#tr_oh.columns = OH_encoder.get_columns()
#te_oh.columns = OH_encoder.get_columns()

# One-hot encoding removed index; put it back
#tr_oh.columns = OH_encoder.get_feature_names()
#te_oh.columns = OH_encoder.get_feature_names()

# Add one-hot encoded columns to our main df new name: tr_fe, te_fe (means feature engeenired)
tr_fe = pd.concat([train, tr_oh], axis=1)
te_fe = pd.concat([test, te_oh], axis=1)

# Dropping irrelevant columns

tr_fe  = tr_fe.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Type','Item_Type'],axis=1)
te_fe = te_fe.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Type','Item_Type'],axis=1)

tr_fe.head()

y = tr_fe['Item_Outlet_Sales']
X = tr_fe.drop('Item_Outlet_Sales', axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8, random_state = 0)

def cross_val(model_name,model,X,y,cv):

    scores = CVS(model, X, y, cv=cv)
    print(f'{model_name} Scores:')
    for i in scores:
        print(round(i,2))
    print(f'Average {model_name} score: {round(scores.mean(),4)}')

!pip install scikit-learn --upgrade
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler to the data
scaler.fit(X)

# Transform the data
X_scaled = scaler.transform(X)

# Create a LinearRegression object
LR = LinearRegression()

# Fit the model to the scaled data
LR.fit(X_scaled, y)

#model
LR = LinearRegression(normalize=True)

#fit
LR.fit(X_train, y_train)

#predict
y_predict = LR.predict(X_test)

#score variables
LR_MAE = round(MAE(y_test, y_predict),2)
LR_MSE = round(MSE(y_test, y_predict),2)
LR_R_2 = round(R2(y_test, y_predict),4)
LR_CS  = round(CVS(LR, X, y, cv=5).mean(),4)

print(f" Mean Absolute Error: {LR_MAE}\n")
print(f" Mean Squared Error: {LR_MSE}\n")
print(f" R^2 Score: {LR_R_2}\n")
cross_val(LR,LinearRegression(),X,y,5)

Random_Forest_Regressor=pd.DataFrame({'y_test':y_test,'prediction':y_predict})
Random_Forest_Regressor.to_csv("Random Forest Regressor.csv")

#model
LS = Lasso(alpha = 0.05)
#fit
LS.fit(X_train,y_train)

#predict
y_predict = LS.predict(X_test)

#score variables
LS_MAE = round(MAE(y_test, y_predict),2)
LS_MSE = round(MSE(y_test, y_predict),2)
LS_R_2 = round(R2(y_test, y_predict),4)
LS_CS  = round(CVS(LS, X, y, cv=5).mean(),4)

print(f" Mean Absolute Error: {LS_MAE}\n")
print(f" Mean Squared Error: {LS_MSE}\n")
print(f" R^2 Score: {LS_R_2}\n")
cross_val(LS,Lasso(alpha = 0.05),X,y,5)

Lasso_Regressor=pd.DataFrame({'y_test':y_test,'prediction':y_predict})
Lasso_Regressor.to_csv("Lasso Regressor.csv")